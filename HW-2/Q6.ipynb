{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sy1Mf6rtRk0"
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xcwn40ivQYJ"
      },
      "source": [
        "def getNextStateandReward(r,c,Action):\n",
        "  #actions : 0 - North, 1 - East, 2 - South, 3 - West\n",
        "  NextS_r=-1\n",
        "  NextS_c=-1\n",
        "  R=-1\n",
        "  if (r==0 and Action==0) or (r==3 and Action==2) or (c==0 and Action==3) or (c==3 and Action==1):\n",
        "      NextState=(r,c)\n",
        "  else:\n",
        "    if Action==0:\n",
        "      NextState=(r-1,c)\n",
        "    elif Action==1:\n",
        "      NextState=(r,c+1)\n",
        "    elif Action==2:\n",
        "      NextState=(r+1,c)\n",
        "    elif Action==3:\n",
        "      NextState=(r,c-1)\n",
        "  return [NextState,R]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLrKecSW0AlB",
        "outputId": "b9f4f1be-9e99-41a9-a775-75245b13de34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "source": [
        "v=np.ones((4,4))\n",
        "v[0][0]=0\n",
        "v[3][3]=0\n",
        "pi=np.ones((4,4,4))/4\n",
        "theta=1e-10\n",
        "stable=False\n",
        "c=0\n",
        "while(not stable):\n",
        "  c+=1\n",
        "  # print(1)\n",
        "  # d=0\n",
        "  print(\"ITERATION - \",c)\n",
        "  while(True):\n",
        "    d=0\n",
        "    for i in range(4):\n",
        "      for j in range(4):\n",
        "        # print(i,j)\n",
        "        if i==j and(i==0 or i==3):\n",
        "          continue\n",
        "        v_cur=v[i][j]\n",
        "        v1=0\n",
        "        for action in range(4):\n",
        "          SNext,R=getNextStateandReward(i,j,action)\n",
        "          x,y=SNext\n",
        "          v1+=pi[i][j][action]*(R+v[x][y])\n",
        "        v[i][j]=v1\n",
        "        d=max(d,abs(v_cur-v[i][j]))\n",
        "    # print(d)\n",
        "    if d<theta:\n",
        "      break\n",
        "  print(\"Policy Evaluation\")\n",
        "  print(v)\n",
        "  stable=True\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      if i==j and(i==0 or i==3):\n",
        "        continue\n",
        "      old_action=np.random.choice([0,1,2,3], p=pi[i][j])\n",
        "      a=[]\n",
        "      for action in range(4):\n",
        "        SNext,R=getNextStateandReward(i,j,action)\n",
        "        x,y=SNext\n",
        "        a.append(R+v[x][y])\n",
        "      optAction=np.argmax(a)\n",
        "      pi[i][j]*=0\n",
        "      pi[i][j][optAction]=1\n",
        "      if old_action!=optAction:\n",
        "        stable=False\n",
        "  print(\"Policy Improvement\")\n",
        "  print(np.argmax(pi, axis=2))\n",
        "  print('')\n",
        "\n",
        "print(\"STABLE POLICY\")\n",
        "print(\"v*\")\n",
        "print(v)\n",
        "print(\"pi*\")\n",
        "print(np.argmax(pi, axis=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ITERATION -  1\n",
            "Policy Evaluation\n",
            "[[  0. -14. -20. -22.]\n",
            " [-14. -18. -20. -20.]\n",
            " [-20. -20. -18. -14.]\n",
            " [-22. -20. -14.   0.]]\n",
            "Policy Improvement\n",
            "[[0 3 3 3]\n",
            " [0 0 3 2]\n",
            " [0 0 2 2]\n",
            " [0 1 1 0]]\n",
            "\n",
            "ITERATION -  2\n",
            "Policy Evaluation\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "Policy Improvement\n",
            "[[0 3 3 2]\n",
            " [0 0 0 2]\n",
            " [0 0 1 2]\n",
            " [0 1 1 0]]\n",
            "\n",
            "ITERATION -  3\n",
            "Policy Evaluation\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "Policy Improvement\n",
            "[[0 3 3 2]\n",
            " [0 0 0 2]\n",
            " [0 0 1 2]\n",
            " [0 1 1 0]]\n",
            "\n",
            "STABLE POLICY\n",
            "v*\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "pi*\n",
            "[[0 3 3 2]\n",
            " [0 0 0 2]\n",
            " [0 0 1 2]\n",
            " [0 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKn7-sbfu10y"
      },
      "source": [
        "## VALUE ITERATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD29OSjxJH05",
        "outputId": "77a8007d-29b1-441c-eebe-4586847500c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "source": [
        "v=np.ones((4,4))\n",
        "v[0][0]=0\n",
        "v[3][3]=0\n",
        "pi=np.ones((4,4,4))/4\n",
        "theta=1e-10\n",
        "stable=False\n",
        "c=0\n",
        "#value iteration\n",
        "print(\"value Iteration\")\n",
        "while(True):\n",
        "  d=0\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      # print(i,j)\n",
        "      if i==j and(i==0 or i==3):\n",
        "        continue\n",
        "      v_cur=v[i][j]\n",
        "      v1=[]\n",
        "      for action in range(4):\n",
        "        SNext,R=getNextStateandReward(i,j,action)\n",
        "        x,y=SNext\n",
        "        v1.append(R+v[x][y])\n",
        "      v[i][j]=max(v1)\n",
        "      d=max(d,abs(v_cur-v[i][j]))\n",
        "  # print(d)\n",
        "  # print()\n",
        "  print(v)  \n",
        "  print(\"\")\n",
        "  if d<theta:\n",
        "    break\n",
        "print(v)\n",
        "# Optimal Policy\n",
        "optPolicy=np.zeros((4,4))\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    # print(i,j)\n",
        "    if i==j and(i==0 or i==3):\n",
        "      continue\n",
        "    v_cur=v[i][j]\n",
        "    v1=[]\n",
        "    for action in range(4):\n",
        "      SNext,R=getNextStateandReward(i,j,action)\n",
        "      x,y=SNext\n",
        "      # v1+=pi[i][j][action]*(R+v[x][y])\n",
        "      v1.append(R+v[x][y])\n",
        "    optPolicy[i][j]=np.argmax(v1)\n",
        "    # v[i][j]=v1\n",
        "    # d=max(d,abs(v_cur-v[i][j]))\n",
        "print(\"Optimal Policy\") \n",
        "print(optPolicy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value Iteration\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "\n",
            "[[ 0. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.]\n",
            " [-1. -1. -1.  0.]]\n",
            "\n",
            "[[ 0. -1. -2. -2.]\n",
            " [-1. -2. -2. -2.]\n",
            " [-2. -2. -2. -1.]\n",
            " [-2. -2. -1.  0.]]\n",
            "\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n",
            "Optimal Policy\n",
            "[[0. 3. 3. 2.]\n",
            " [0. 0. 0. 2.]\n",
            " [0. 0. 1. 2.]\n",
            " [0. 1. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHrNbrUTyD_y"
      },
      "source": [
        "The bug is handled automatically by the argmax function, it always picks the first argument with the maximum value, so if 1 and 3 are the maximum arguments, it always picks 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJL11LeexQ6r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}